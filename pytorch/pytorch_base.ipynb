{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6212, 0.9585, 0.0607],\n",
      "        [0.5718, 0.6522, 0.1558]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "print(rand_tensor)\n",
    "ones_tensor = torch.ones(shape)\n",
    "print(ones_tensor)\n",
    "zeors_tensor = torch.zeros(shape)\n",
    "print(zeors_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 0, 0, 0],\n",
      "        [1, 2, 2, 0],\n",
      "        [0, 0, 2, 0],\n",
      "        [1, 0, 2, 2]])\n",
      "tensor([2, 0, 0, 0])\n",
      "<built-in method item of Tensor object at 0x000001E834C38BD0>\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randint(0,3,(4,4))\n",
    "print(tensor)\n",
    "print(tensor[0])\n",
    "print(tensor[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0],\n",
      "        [1, 2, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0],\n",
      "        [0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0],\n",
      "        [1, 0, 2, 2, 1, 0, 2, 2, 1, 0, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "t1  = torch.cat([tensor, tensor, tensor], dim = 1 )\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.ones(3,2)+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18., 18., 18.],\n",
       "        [18., 18., 18.],\n",
       "        [18., 18., 18.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor @ tensor.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3531, 0.4553],\n",
      "        [0.7100, 0.1220],\n",
      "        [0.2658, 0.9520]])\n"
     ]
    }
   ],
   "source": [
    "y3 = torch.rand_like(tensor)\n",
    "print(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[18., 18., 18.],\n",
      "        [18., 18., 18.],\n",
      "        [18., 18., 18.]])\n"
     ]
    }
   ],
   "source": [
    "torch.matmul(tensor, tensor.T, out = y3)\n",
    "print(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.],\n",
      "        [9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "z1 = tensor * tensor\n",
    "print(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.],\n",
      "        [9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "z2 = tensor.mul(tensor)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2949, 0.2184],\n",
      "        [0.4246, 0.1506],\n",
      "        [0.7866, 0.6864]])\n"
     ]
    }
   ],
   "source": [
    "z3 = torch.rand_like(tensor)\n",
    "print(z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.],\n",
      "        [9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "torch.mul(tensor, tensor, out = z3)\n",
    "print(z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum().item()\n",
    "print(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8., 8.],\n",
      "        [8., 8.],\n",
      "        [8., 8.]])\n"
     ]
    }
   ],
   "source": [
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([3., 3., 3., 3., 3.])\n",
      "[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(t)\n",
    "n = t.numpy()\n",
    "print(n)\n",
    "t.add_(2)\n",
    "print(t)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 22],\n",
      "        [43, 50]], dtype=torch.int32)\n",
      "134\n",
      "tensor([[ 5., 12.],\n",
      "        [21., 32.]])\n"
     ]
    }
   ],
   "source": [
    "#실습1-1\n",
    "tensor1 = [[1,2],[3,4]]\n",
    "tensor2 = [[5,6],[7,8]]\n",
    "np_array1 = np.array(tensor1)\n",
    "np_array2 = np.array(tensor2)\n",
    "\n",
    "tensor1 = torch.from_numpy(np_array1)\n",
    "tensor2 = torch.from_numpy(np_array2)\n",
    "z1 = tensor1 @ tensor2\n",
    "print(z1)\n",
    "\n",
    "#실습1-2\n",
    "print(z1.sum().item())\n",
    "\n",
    "#실습1-3\n",
    "torch.mul(tensor1, tensor2, out = z2)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ppjj2\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\build\\aten\\src\\ATen/core/TensorBody.h:482.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,2, requires_grad=True)\n",
    "y1 = x + 2\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.)\n",
      "tensor(21., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad = True)\n",
    "y = 3*x**2 + 4*x + 1\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.) tensor(4.)\n",
      "tensor(5., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0, requires_grad = True)\n",
    "z = torch.tensor(2.0, requires_grad = True)\n",
    "\n",
    "y = x**3 + z**2\n",
    "y.backward()\n",
    "print(x.grad, z.grad)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.7641,  0.3131,  1.8676,  0.9501,  0.1440,  0.7610,  0.4439,  0.9787,\n",
      "         1.4941, -0.1032])\n",
      "tensor([ 0.4002, -0.8541, -0.9773, -0.1514,  1.4543,  0.1217,  0.3337,  2.2409,\n",
      "        -0.2052,  0.4106])\n",
      "Epoch    0/100000 w1: 0.053 w2: 0.053 b: 0.083 Cost: 8964.013672\n",
      "Epoch 10000/100000 w1: 13.134 w2: 13.134 b: 4.511 Cost: 1.660413\n",
      "Epoch 20000/100000 w1: 13.544 w2: 13.544 b: 4.034 Cost: 1.580720\n",
      "Epoch 30000/100000 w1: 13.554 w2: 13.554 b: 4.022 Cost: 1.580665\n",
      "Epoch 40000/100000 w1: 13.554 w2: 13.554 b: 4.022 Cost: 1.580665\n",
      "Epoch 50000/100000 w1: 13.554 w2: 13.554 b: 4.022 Cost: 1.580665\n",
      "Epoch 60000/100000 w1: 13.554 w2: 13.554 b: 4.022 Cost: 1.580665\n",
      "Epoch 70000/100000 w1: 13.554 w2: 13.554 b: 4.022 Cost: 1.580665\n",
      "Epoch 80000/100000 w1: 13.554 w2: 13.554 b: 4.022 Cost: 1.580665\n",
      "Epoch 90000/100000 w1: 13.554 w2: 13.554 b: 4.022 Cost: 1.580665\n",
      "Epoch 100000/100000 w1: 13.554 w2: 13.554 b: 4.022 Cost: 1.580665\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn #뉴럴 네트워크, 신경망을 구성하는데 필요한 모든 구성 요소를 제공\n",
    "import torch.nn.functional as F # convolution function, pooling function, activation function, dropout function, loss function 등의 기능 제공\n",
    "import torch.optim as optim #optimizer 제공\n",
    "\n",
    "w1 = torch.zeros(1, requires_grad=True)\n",
    "w2 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "X = torch.FloatTensor([[ 1.76405235,  0.40015721],\n",
    " [ 0.3130677,  -0.85409574],\n",
    " [ 1.86755799, -0.97727788],\n",
    " [ 0.95008842, -0.15135721],\n",
    " [ 0.14404357,  1.45427351],\n",
    " [ 0.76103773,  0.12167502],\n",
    " [ 0.44386323,  0.33367433],\n",
    " [ 0.97873798,  2.2408932 ],\n",
    " [ 1.49407907, -0.20515826],\n",
    " [-0.10321885,  0.4105985 ]])\n",
    "\n",
    "y = torch.FloatTensor([ 63.53688815, -71.72648252, -61.68390971,   1.57941977, 140.99124416,\n",
    "  25.4497451,   40.69691806, 229.37436452,   6.57023041,  42.57804267])\n",
    "\n",
    "X1 = X[:,0]\n",
    "print(X1)\n",
    "X2 = X[:,1]\n",
    "print(X2)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD([w1,w2, b], lr=1e-3)\n",
    "\n",
    "\n",
    "nb_epochs = 100000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    hypothesis = X1*w1 + X2*w2 + b\n",
    "\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad() # 미분한 값들은 누적되는 특징이 있기 때문에 0으로 초기화\n",
    "    cost.backward() # 역전파\n",
    "    optimizer.step() # 역전파시에 계산된 값으로 매개변수 수정\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 10000 ==0:\n",
    "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, w1.item(),w1.item(), b.item(), cost.item()\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
